{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457dee47-c383-4225-81d4-e6abc4507add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c6009a6-a29a-40b3-bb26-617bcb01d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(32 * 24 * 24, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 24 * 24)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535efcc5-8f22-4a51-a835-898feccfd2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, labels_df, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load labels from CSV file\n",
    "        self.labels_df = labels_df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.labels_df.iloc[idx, 0]) + '.tif'\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        # Extract label from CSV\n",
    "        label = self.labels_df.iloc[idx, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_dir = 'C:\\\\Users\\\\natha\\Documents\\\\PythonNotebooks\\\\data\\\\Cancer\\\\'\n",
    "df = pd.read_csv(os.path.join(data_dir, 'train_labels.csv'))\n",
    "train = df.sample(frac=0.85, random_state=42)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "image_dir = os.path.join(data_dir, 'train')\n",
    "train_data = CustomDataset(image_dir, train, transform=transform)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_data = CustomDataset(image_dir, test, transform=transform)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f156762-7c5e-440d-b6e1-d32fbb275ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]\n",
      "Train Loss: 0.4139\n",
      "Train Accuracy: 0.8168\n",
      "Train False Negative Rate: 0.2677\n",
      "Test Loss: 0.3483\n",
      "Test Accuracy: 0.8491\n",
      "Test False Negative Rate: 0.2692\n",
      "Epoch [2/3]\n",
      "Train Loss: 0.3241\n",
      "Train Accuracy: 0.8616\n",
      "Train False Negative Rate: 0.1884\n",
      "Test Loss: 0.3134\n",
      "Test Accuracy: 0.8685\n",
      "Test False Negative Rate: 0.1642\n",
      "Epoch [3/3]\n",
      "Train Loss: 0.2759\n",
      "Train Accuracy: 0.8849\n",
      "Train False Negative Rate: 0.1536\n",
      "Test Loss: 0.3190\n",
      "Test Accuracy: 0.8627\n",
      "Test False Negative Rate: 0.2559\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0.0\n",
    "    running_test_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    false_negative_train = 0\n",
    "    total_positive_train = 0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    false_negative_test = 0\n",
    "    total_positive_test = 0\n",
    "    \n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()  # Convert labels to float\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))  # Unsqueeze labels to match output shape\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_train += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        \n",
    "        # Compute false negative rate\n",
    "        false_negative_train += ((predicted == 0) & (labels.unsqueeze(1) == 1)).sum().item()\n",
    "        total_positive_train += (labels == 1).sum().item()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            \n",
    "            running_test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct_test += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            \n",
    "            # Compute false negative rate\n",
    "            false_negative_test += ((predicted == 0) & (labels.unsqueeze(1) == 1)).sum().item()\n",
    "            total_positive_test += (labels == 1).sum().item()\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_dataloader.dataset)\n",
    "    epoch_test_loss = running_test_loss / len(test_dataloader.dataset)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    train_accuracy = correct_train / total_train\n",
    "    test_accuracy = correct_test / total_test\n",
    "    \n",
    "    # Calculate false negative rate\n",
    "    false_negative_rate_train = false_negative_train / total_positive_train\n",
    "    false_negative_rate_test = false_negative_test / total_positive_test\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'Train Loss: {epoch_train_loss:.4f}')\n",
    "    print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Train False Negative Rate: {false_negative_rate_train:.4f}')\n",
    "    print(f'Test Loss: {epoch_test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "    print(f'Test False Negative Rate: {false_negative_rate_test:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'files/cancer_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c6017e6-1f1f-4dba-9367-61060163ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "testing_folder = 'C:\\\\Users\\\\natha\\Documents\\\\PythonNotebooks\\\\data\\\\Cancer\\\\test\\\\'\n",
    "\n",
    "# Define transformations to be applied to your images\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define function to load and preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image_transform(image)\n",
    "    return image.unsqueeze(0) \n",
    "\n",
    "# Load your trained model\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load(\"files/cancer_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image_class(image_path, model):\n",
    "    image = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        predicted_class = torch.round(output).item()\n",
    "    return predicted_class\n",
    "\n",
    "rows = []\n",
    "# Iterate through images in the folder and classify them\n",
    "for image_file in os.listdir(testing_folder):\n",
    "    image_path = os.path.join(testing_folder, image_file)\n",
    "    predicted_class = predict_image_class(image_path, model)\n",
    "    rows.append({'id': image_file.split('.')[0], 'label': int(predicted_class)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62426a36-91f9-45ca-8ff0-a9cd6bdeafb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57458"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ca4aeb6-058f-4823-949a-e9c82a3a16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=rows).to_csv('files/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
